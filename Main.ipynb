{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdf1e3e-3a2d-4941-b2e3-addde32fba65",
   "metadata": {},
   "source": [
    "**Use Case - Using openai to extract the outcome of all the available judgements in the court of criminal appeal (superior)**\n",
    "\n",
    "Up to July 23 there were 139 appeals available on e-courts. We will be using openAI chat completion to determine the outcome of the appeals. Only 27 were successful/partially successful, 112 were rejected. \n",
    "\n",
    "The data was extracted previously and stored in a SQL database. This is a particularly interesting task because some of the judgements (quite a few) are in Maltese. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11064fc-d083-4cf4-a3b7-d856e49f4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from easygoogletranslate import EasyGoogleTranslate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb2e0d-f06f-4877-b53b-395c8e7ccfe2",
   "metadata": {},
   "source": [
    "Importing the dataset from sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4febb9f9-bb20-4970-a7a3-4f4634806099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grupp\\AppData\\Local\\Temp\\ipykernel_8308\\2855617603.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Connection details\n",
    "conn_str = (\n",
    "    r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    r'SERVER=RG_LAPTOP\\SQLEXPRESS;'\n",
    "    r'DATABASE=master;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# SQL query\n",
    "query = '''\n",
    "    SELECT *\n",
    "    FROM CourtJudgementsText\n",
    "    WHERE CaseNumber IN (\n",
    "        SELECT CaseNumber\n",
    "        FROM CourtJudgements_Staging\n",
    "        WHERE Court LIKE '%OF CRIMINAL APPEAL (SUPERIOR)%'\n",
    "    )\n",
    "'''\n",
    "\n",
    "# Establishing the connection\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Executing the query and fetching the data into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Closing the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6f219-f104-45f9-b5fa-51da10774b73",
   "metadata": {},
   "source": [
    "Thats them - after reading a few it was evident that the last 300 words should be more than enough to get 'most' right. Some judgements are more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eefbfba-4049-4343-a14c-2dcc86519178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CaseNumber                                       JudgmentText  \\\n",
      "0        72770  Kopja Informali ta' Sentenza  \\nPagna 1 minn 3...   \n",
      "1       136696  1 \\n  \\nThe Court of Criminal Appeal  \\n \\nHis...   \n",
      "2       136697  1 \\n \\n \\n \\nQORTI TA` L -APPELL KRIMINALI  \\n...   \n",
      "3       136698  1 \\n  \\nThe Court of Criminal Appeal  \\n \\nHis...   \n",
      "4       120005  1 \\n QORTI TAL -APPELL KRIMINALI  \\nS.T.O. PRI...   \n",
      "..         ...                                                ...   \n",
      "134     138528  1 \\n \\n \\n \\nQORTI TA` L -APPELL KRIMINALI  \\n...   \n",
      "135     113796  1 \\n  \\n \\n \\nQORTI TA'  L-APPELL KRIMINALI  \\...   \n",
      "136     113797  1 \\n  \\n \\n \\nQORTI TA'  L-APPELL KRIMINALI  \\...   \n",
      "137     113799  1 \\n  \\n \\n \\nQORTI TA'  L-APPELL KRIMINALI  \\...   \n",
      "138      17727  Kopja Informali ta' Sentenza  \\nPagna 1 minn 1...   \n",
      "\n",
      "                                              last_300  \n",
      "0    dealt with was outside the broad range of pena...  \n",
      "1    Institute of Bail it is evident that no appeal...  \n",
      "2    għaliex il liġi stess b deroga għar regoli ġen...  \n",
      "3    Frar 2012 App Sup 8 mogħti lil l esperti rispe...  \n",
      "4    nullita tal operazzjoni u del resto din qatt m...  \n",
      "..                                                 ...  \n",
      "134  ippreżenta l eżebiti quddiem il Qorti Istrutto...  \n",
      "135  il vittma Ma dan il Qorti qed izzid ukoll illi...  \n",
      "136  gudikatura huwa wiehed mill principji fundamen...  \n",
      "137  hadet judicial notice tad decizjonijiet ir Rep...  \n",
      "138  evidence which of the two possible hypotheses ...  \n",
      "\n",
      "[139 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract the last 300 words from a text\n",
    "def extract_last(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    last_100_words = ' '.join(words[-300:])\n",
    "    return last_100_words\n",
    "\n",
    "# Apply the function to create the 'last_100' column\n",
    "df['last_300'] = df['JudgmentText'].apply(extract_last)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639b204-1771-49ed-994c-52e843cae8a6",
   "metadata": {},
   "source": [
    "Using google translate for the last 300 words. Tried to use chatGPT with Maltese Language with little success. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607e653d-28d8-4d0a-a15f-5781aa395fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(df):\n",
    "    translator = EasyGoogleTranslate(\n",
    "        source_language='mt',\n",
    "        target_language='en',\n",
    "        timeout=10\n",
    "    )\n",
    "\n",
    "    translated_texts = []\n",
    "    total_rows = len(df)\n",
    "    progress_bar = tqdm(total=total_rows, desc=\"Translating\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['last_300']\n",
    "        chunk_size = 5000  # Set the maximum chunk size for translation\n",
    "        chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "        translated_chunks = [translator.translate(chunk) for chunk in chunks]\n",
    "        translated_text = ' '.join(translated_chunks)\n",
    "        translated_texts.append(translated_text)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    df['last_300_e'] = translated_texts\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7157c-c1c0-4c45-9d30-e09d17eda589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = translate_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2fec8-ea44-4812-bc0b-f22a0997c24d",
   "metadata": {},
   "source": [
    "The next step is to use openai (gpt-3.5-turbo) to evaluate the translated extracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46503a81-216c-4849-85c4-3e6419b91a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "# Set API key and model\n",
    "api_key = 'sk-xxxx'\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843587d-9989-4b90-8b8a-0df53ef1673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(article_body):\n",
    "\n",
    "    retries = 1  # Number of retries in case of a disconnection\n",
    "    for retry in range(1, retries + 2):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"Imagine you are a legal journalist. Each text body is the last 300 words of a Maltese Court Judgment from Criminal Appeal. Your task is to \n",
    "                     describe the outcome of the appeal in about 100 words. Use short sentences when possible.\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Body: {article_body}\"}\n",
    "                ],\n",
    "                max_tokens=120,\n",
    "                temperature=0.0\n",
    "            )\n",
    "            return response.choices[0].message['content']\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            if retry <= retries:\n",
    "                print(f\"Retrying in 5 seconds... (Attempt {retry})\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(\"Max retries reached. Skipping this article.\")\n",
    "    return \"Error: Unable to generate response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b712f4-0b08-4fd4-906c-e00570cc099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a progress bar using tqdm\n",
    "pbar = tqdm(total=10)  # Set the total to 10 for the first 10 rows\n",
    "\n",
    "# Generate responses for each judgment text and store in \"Output_1\" column\n",
    "for index, row in itertools.islice(df.iterrows(), 10):  # Use itertools.islice to limit the loop to the first 10 rows\n",
    "    df.at[index, 'GPT_Summary'] = generate_response(row['last_300_e'])\n",
    "    pbar.update(1)\n",
    "    if index == 9:  # Break the loop after processing the first 10 rows\n",
    "        break\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a334a6-339a-4b08-9b3e-63dbee2b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a progress bar using tqdm\n",
    "pbar = tqdm(total=len(df))\n",
    "\n",
    "# Generate responses for each judgment text and store in \"Output_1\" column\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'GPT_Summary'] = generate_response(row['last_300_e'])\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcde650-43df-4f4f-a03c-1152be124daf",
   "metadata": {},
   "source": [
    "The next step was manually checking a portion of the replies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3916f5ae-2161-4adc-ac21-eb0a4cbe631c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
